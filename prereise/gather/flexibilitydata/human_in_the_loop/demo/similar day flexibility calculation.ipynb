{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1531b359-3fd1-4d4b-a585-8a63aee0b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from functions import *\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36c45abd-6367-4d18-b3c5-f810bed98d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.normpath(os.getcwd() + os.sep + os.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115cbea4-c483-4a16-bcad-38be44e4a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DR_path = os.path.join(path, 'Data', 'Similar Day', 'DR')\n",
    "baseline_path = os.path.join(path, 'Data', 'Similar Day', 'Baseline')\n",
    "flex_path = os.path.join(path, 'Data', 'Flexibility', 'Raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a1b2b2-96ed-4aa4-b8d0-8350a36edd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going through the clustered files and calculate the flexibility by taking the ratio of power consumption during the DR time period and the baseline\n",
    "\n",
    "for dr_file in os.listdir(DR_path):\n",
    "    \n",
    "    # Some days did not have any matching weather patterns to one of the cluster so an empty file might be saved, this helps to filter out those files\n",
    "    if os.stat(os.path.join(DR_path, dr_file)).st_size > 2:\n",
    "        if os.path.exists(os.path.join(DR_path, dr_file)):\n",
    "            dr = pd.read_csv(os.path.join(DR_path, dr_file))\n",
    "            baseline_file = dr_file.split(sep='.')[0] + ' baseline.csv'\n",
    "            \n",
    "            if os.path.exists(os.path.join(baseline_path, baseline_file)):\n",
    "                baseline = pd.read_csv(os.path.join(baseline_path, baseline_file))\n",
    "                flex_file = dr_file.split(sep='.')[0] + ' flex.csv'\n",
    "                \n",
    "                dr = dr.groupby(np.arange(len(dr)) // 4).sum()\n",
    "                baseline = baseline.groupby(np.arange(len(baseline)) // 4).sum()\n",
    "                \n",
    "                # Find flex by calculating the ratio between usage during DR and usage from baseline\n",
    "                # Smaller the better -> if baseline is larger, then the value is smaller\n",
    "                ratio = pd.DataFrame(dr.values / baseline.values)\n",
    "                ratio.columns = dr.columns\n",
    "                ratio.to_csv(os.path.join(flex_path, flex_file), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71589675-b3c2-4368-aec5-2488e8928809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all users from the files\n",
    "\n",
    "users = []\n",
    "for file in os.listdir(os.path.join(flex_path)):\n",
    "    temp = file.split(sep=' ')[0]\n",
    "    if temp not in users:\n",
    "        users.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ef319fa-a321-4e73-ba7a-84f679ba715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [0, 1, 2]\n",
    "title = ['Summer Weekday', 'Summer Weekend']\n",
    "\n",
    "# Helper function to see if the file exists or not\n",
    "def read_df_exist(path):\n",
    "    if os.path.exists(path):\n",
    "        return pd.read_csv(path)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaab2cc5-3b83-4cf2-8c1b-3e2cae69ce9b",
   "metadata": {},
   "source": [
    "The next section finds all of the time sections from the same day, of the same user, and from the same cluster number into one file\n",
    "The second method is to find all of the time sections from the same day, of the same user but from multiple clusters into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c92698e-0fa7-4c11-8381-9198109f174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section creates helper dictionaries that will be used to piece together all of the time sections spread across different clusters of the same user\n",
    "\n",
    "# Gathers all of the users\n",
    "users = []\n",
    "for file in os.listdir(os.path.join(path, 'Data', 'Flexibility', 'Raw')):\n",
    "    user = file.split(sep=' ')[0]\n",
    "    users.append(user)\n",
    "    \n",
    "users = set(users)\n",
    "\n",
    "# Creates a dictionary with the users as the key and the file names under the user as array\n",
    "files = {}\n",
    "for user in users:\n",
    "    files[user] = []\n",
    "    for file in os.listdir(os.path.join(path, 'Data', 'Flexibility', 'Raw')):\n",
    "        if file.startswith(user):\n",
    "            files[user].append(file)\n",
    "\n",
    "# Reads in all of the raw flexibility files for that user\n",
    "users = {}\n",
    "for key, items in files.items():\n",
    "    users[key] = {}\n",
    "    for item in items:\n",
    "        users[key][item] = pd.read_csv(os.path.join(path, 'Data', 'Flexibility', 'Raw', item))\n",
    "\n",
    "# Gathers all of the dates in each user's flexibility files\n",
    "dates = []\n",
    "for key, items in users.items():\n",
    "    for file, df in users[key].items():\n",
    "        dates.append(df.columns)\n",
    "\n",
    "# All unique days\n",
    "days = []\n",
    "for i in dates:\n",
    "    for j in i:\n",
    "        days.append(j)\n",
    "\n",
    "days = set(days)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a7ac559-559a-4435-97d9-55e51b376cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Winter, create mapping; only need to run once\n",
    "\n",
    "winter_days = {}\n",
    "start = datetime(2005,12,31)\n",
    "\n",
    "for day in days:\n",
    "    winter_days[start] = day\n",
    "    start = start + timedelta(days=1)\n",
    "\n",
    "days_temp = []\n",
    "for key, item in winter_days.items():\n",
    "    days_temp.append(key)\n",
    "\n",
    "winter_days = {}\n",
    "start = datetime(2017, 1, 1)\n",
    "\n",
    "for day in days_temp:\n",
    "    winter_days[start] = day\n",
    "    start = start + timedelta(days=1)\n",
    "    \n",
    "with open(os.path.join(path, 'Data', 'summer2winter days.pickle'), 'wb') as handle:\n",
    "    pickle.dump(winter_days, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f28fcd56-f54c-41e0-9991-621e62c395c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This returns a nested dictionary that first has the user id as the key, then on the inner dictionary, it has the date as the key,\n",
    "# the items are the flexibility files that contains that day.\n",
    "\n",
    "user_day_dict = {}\n",
    "\n",
    "for user in users:\n",
    "    user_day_dict[user] = {}\n",
    "    for day in days:\n",
    "        user_day_dict[user][day] = []\n",
    "        for i in users[user]:\n",
    "            if day in users[user][i].columns:\n",
    "                user_day_dict[user][day].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01147b37-3492-4aec-91a8-036ad59d901f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This outputs the flexibility profile for all users for the full day, instead of 4 sections\n",
    "\n",
    "for user, days in user_day_dict.items():\n",
    "    full_df = pd.DataFrame()\n",
    "    \n",
    "    for i in days:\n",
    "        temp = days[i]\n",
    "        \n",
    "        # See if the time section contains all hours which is 4 hours. \n",
    "        if len(temp) == 4:\n",
    "            for file in temp:             \n",
    "                temp_df = pd.read_csv(os.path.join(path, 'Data', 'Flexibility', 'Raw', file))\n",
    "                temp_df = temp_df[[i]]\n",
    "                if 'Morning' in file:\n",
    "                    morning = temp_df\n",
    "                elif 'Noon' in file:\n",
    "                    noon = temp_df\n",
    "                elif 'Evening' in file:\n",
    "                    evening = temp_df\n",
    "                elif 'Night' in file:\n",
    "                    night = temp_df\n",
    "\n",
    "            full_df.insert(0, i, pd.concat((morning, noon, evening, night)))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    full_df.reset_index(inplace=True, drop=True)\n",
    "    full_df.to_csv(os.path.join(path, 'Data', 'Flexibility', 'Summer User Full', f'{user} full flex.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind Data From NOAA's RAP model\n",
    "---\n",
    "\n",
    "**NOAA**: National Oceanic and Atmospheric Administration\n",
    "\n",
    "**RAP**: Rapid Refresh  \n",
    "Information can be found at the following url:\n",
    "https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/rapid-refresh-rap\n",
    "\n",
    "Data can be retrieved using the NetCDF Subset Service (NCSS). Information on this protocol are available at: https://www.unidata.ucar.edu/software/thredds/current/tds/reference/NetcdfSubsetServiceReference.html\n",
    "\n",
    "The Rapid Refresh (RAP) numerical weather model is run by the National Centers for Environmental Prediction (NCEP), which is part of of the NOAA. Multiple data sources go into the generation of RAP model: commercial aircraft weather data, balloon data, radar data, surface observations, and satellite data. The model generates data down to a 13 km resolution horizontal grid every hour. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sites Location\n",
    "The location (longitude and latitude) of the wind farms in the Western grid are retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import westernintnet\n",
    "grid = westernintnet.WesternIntNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_farm = grid.genbus.groupby('type').get_group('wind')\n",
    "n_target = len(wind_farm)\n",
    "\n",
    "print(\"There are %d wind farms in the Western grid.\" % n_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_farm.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_target = wind_farm.lon.values\n",
    "lat_target = wind_farm.lat.values\n",
    "id_target  = wind_farm.index.values\n",
    "capacity_target = wind_farm.GenMWMax.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Wind Data\n",
    "\n",
    "### A.  Downloading Files from NCEP Server and Filling out Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path to all files we will download is created. These are 1 hour resolution files for the year 2016. Note that 2016 is a leap year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://www.ncei.noaa.gov/thredds/ncss/rap130anl/'\n",
    "\n",
    "start = datetime.datetime.strptime('2016-01-01', '%Y-%m-%d')\n",
    "end = datetime.datetime.strptime('2016-12-31', '%Y-%m-%d')\n",
    "step = datetime.timedelta(days=1)\n",
    "\n",
    "files = []\n",
    "while start <= end:\n",
    "    ts = start.strftime('%Y%m%d')\n",
    "    url = path + '2016'+ ts[4:6] + '/' + ts + '/'\n",
    "    for h in range(10000,12400,100):\n",
    "        files.append(url + 'rap_130_' + ts + '_' + str(h)[1:] + '_000.grb2?')\n",
    "    start += step\n",
    "\n",
    "print(\"There are %d files\" % len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The U and V components of the wind speed at 10m and 80 meters are the only variables that will be enclosed in the files. Note that We don't need to consider the entire grid. We retrieve only the variables for a predefined bounding box. The boundaries of the box have been chosen according to the northernmost, easternmost, southernmost and westernmost wind farms.\n",
    "\n",
    "The data will be downloaded in the NetCDF (Network Common Data Form) format. Instructions given in https://www.unidata.ucar.edu/software/thredds/current/tds/reference/NetcdfSubsetServiceReference.html have been very helpful to access these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "var = 'var=u-component_of_wind_height_above_ground' + '&' + \\\n",
    "      'var=v-component_of_wind_height_above_ground'\n",
    "\n",
    "# Bounding Box\n",
    "box = 'north=49&west=-122&east=-102&south=32&disableProjSubset=on&horizStride=1&addLatLon=true'\n",
    "\n",
    "# Data Format\n",
    "extension = 'accept=netCDF'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each farm, we need to find the closest location on the grid. To do so, we calculate the angular distance between the direction of the wind farm and all the directions of the grid. Two functions are defined on the grid below. The first one, `ll2uv` converts the longitude and latitude of a location to its corresponding unit vector ($x$,$y$,$z$). The second function, `angular_distance`, calculates the scalar product between two vectors and returns the subtended angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ll2uv(lon, lat):\n",
    "    cos_lat = math.cos(math.radians(lat))\n",
    "    sin_lat = math.sin(math.radians(lat))\n",
    "    cos_lon = math.cos(math.radians(lon))\n",
    "    sin_lon = math.sin(math.radians(lon))\n",
    "    \n",
    "    uv = []\n",
    "    uv.append(cos_lat * cos_lon)\n",
    "    uv.append(cos_lat * sin_lon)\n",
    "    uv.append(sin_lat)\n",
    "    \n",
    "    return uv\n",
    "\n",
    "\n",
    "def angular_distance(uv1, uv2):    \n",
    "    cos_angle = uv1[0]*uv2[0] + uv1[1]*uv2[1] + uv1[2]*uv2[2]\n",
    "    if cos_angle >= 1:\n",
    "        cos_angle = 1\n",
    "    if cos_angle <= -1:\n",
    "        cos_angle = -1\n",
    "    angle = math.degrees(math.acos(cos_angle))\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NREL (National Renewable Energy Laboratory) provides generic power curves to estimate wind power output. Three classes of turbines have been defined, which depends on the available wind speed. An offshore class has also been developed. For each class a power curve is given to convert windspeed at 100m to power output. More information can be found in the following document: https://www.nrel.gov/docs/fy14osti/61714.pdf\n",
    "\n",
    "Note that we use the **IEC class 2** power curve for all the location here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PowerCurves = pd.read_csv('../IECPowerCurves.csv')\n",
    "\n",
    "def get_power(wspd, turbine):\n",
    "    match  = (PowerCurves['Speed bin (m/s)'] <= np.ceil(wspd)) & (PowerCurves['Speed bin (m/s)'] >= np.floor(wspd))\n",
    "    if not match.any():\n",
    "        return 0\n",
    "    values = PowerCurves[turbine][match]\n",
    "    return np.interp(wspd,PowerCurves[turbine][match].index.values,PowerCurves[turbine][match].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data are collected below and a dataframe is filled out. Note that some files are missing. An interpolation will be used later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "missing = []\n",
    "target2grid = OrderedDict()\n",
    "data = pd.DataFrame({'plantID':[], 'U':[], 'V':[], 'Pout':[], 'ts':[], 'tsID':[]})\n",
    "dt = datetime.datetime.strptime('2016-01-01', '%Y-%m-%d')\n",
    "step = datetime.timedelta(hours=1)\n",
    "\n",
    "\n",
    "for i, file in tqdm_notebook(enumerate(files)):\n",
    "    if i % 1000 == 0: time.sleep(300)\n",
    "    query = file + var + '&' + box + '&' + extension\n",
    "    request = requests.get(query)\n",
    "    \n",
    "    data_tmp = pd.DataFrame({'plantID':id_target, 'ts':[dt]*n_target, 'tsID':[i+1]*n_target})\n",
    "    \n",
    "    if request.status_code == 200:\n",
    "        with open('tmp.nc', 'wb') as f: \n",
    "            f.write(request.content)\n",
    "        tmp = Dataset('tmp.nc', 'r')\n",
    "        lon_grid = tmp.variables['lon'][:].flatten()\n",
    "        lat_grid = tmp.variables['lat'][:].flatten()\n",
    "        u_wsp = tmp.variables['u-component_of_wind_height_above_ground'][0,1,:,:].flatten()\n",
    "        v_wsp = tmp.variables['v-component_of_wind_height_above_ground'][0,1,:,:].flatten()\n",
    "            \n",
    "        n_grid = len(lon_grid)\n",
    "        if data.empty:\n",
    "            # The angular distance is calculated once. The target to grid correspondence is stored in a dictionary.\n",
    "            for j in range(n_target):\n",
    "                uv_target = ll2uv(lon_target[j], lat_target[j])\n",
    "                distance = [angular_distance(uv_target, ll2uv(lon_grid[k],lat_grid[k])) for k in range(n_grid)]                    \n",
    "                target2grid[id_target[j]] = np.argmin(distance)\n",
    "         \n",
    "        data_tmp['U'] = [u_wsp[target2grid[id_target[j]]] for j in range(n_target)]\n",
    "        data_tmp['V'] = [v_wsp[target2grid[id_target[j]]] for j in range(n_target)]\n",
    "        data_tmp['Pout'] = np.sqrt(pow(data_tmp['U'],2) + pow(data_tmp['V'],2))\n",
    "        data_tmp['Pout'] = [get_power(val, 'IEC class 2')*capacity_target[j] for j, val in enumerate(data_tmp['Pout'].values)]\n",
    "        \n",
    "        tmp.close()\n",
    "        os.remove('tmp.nc')\n",
    "    else:\n",
    "        print(\"File %s is missing\" % file.split('/')[-1])\n",
    "        missing.append(file)\n",
    "        \n",
    "        # missing data are set to -99.\n",
    "        data_tmp['U'] = [-99] * n_target\n",
    "        data_tmp['V'] = [-99] * n_target         \n",
    "        data_tmp['Pout'] = [-99] * n_target\n",
    "        \n",
    "    data = data.append(data_tmp, ignore_index=True, sort=False)   \n",
    "        \n",
    "    dt += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['plantID'] = data['plantID'].astype(np.int32)\n",
    "data['tsID'] = data['tsID'].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['tsID', 'plantID'], inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe is saved on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('western_wind_output_2016_unfilled.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Imputing Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_impute = data[data.Pout == -99].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.DatetimeIndex(data['ts'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each missing entry, we calculate the mean of the U and V components of the wind speed of all the entries that have the same location (`plantID`), the same month, the same hour and, of course, are missing. Using the derived U and V components of the wind speed, we compute the wind power output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in tqdm_notebook(enumerate(to_impute)):\n",
    "    if i % len(wind_farm) == 0:\n",
    "        year, month, day, hour = dates[j].year, dates[j].month, dates[j].day, dates[j].hour\n",
    "        select = data[(dates.month == month) &  (dates.hour == hour) & (data.Pout != -99)]\n",
    "    \n",
    "    k = data.loc[j].plantID\n",
    "    select = select[select.plantID == k]\n",
    "    \n",
    "    data.at[j,'U'] = select['U'].mean()\n",
    "    data.at[j,'V'] = select['V'].mean()\n",
    "    data.at[j,'Pout'] = get_power(np.sqrt(data.loc[j].U**2 + data.loc[j].V**2), 'IEC class 2') * wind_farm.loc[k].GenMWMax\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frame is saved on disk. The csv file is the one used by the simulation engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('western_wind_output_2016.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"western_wind_output_2016_ts.csv\"\n",
    "data.to_csv(name, header=None, index=False, columns=['tsID','plantID','Pout'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
